{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-16T01:56:37.688710Z",
     "start_time": "2025-04-16T01:56:35.164123Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "from torch import Tensor, nn\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from tqdm import tqdm\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "from koopman.simulation.simulator import simulate_batch\n",
    "from koopman.simulation.systems import Pendulum"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T01:56:38.318868Z",
     "start_time": "2025-04-16T01:56:38.314530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_random_smooth_controls(N, T):\n",
    "    dt = 0.05\n",
    "    w = np.random.randn(N, T, 1) * np.sqrt(dt)\n",
    "    b = np.cumsum(w, axis=1)\n",
    "    b_smooth = gaussian_filter1d(b, sigma=10, axis=1)\n",
    "\n",
    "    return b_smooth"
   ],
   "id": "5d3ad52ee964ff22",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T01:52:36.127770Z",
     "start_time": "2025-04-16T01:52:36.048919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "params = Pendulum.Params(\n",
    "    m=1, l=1, g=9.81, b=0.0\n",
    ")\n",
    "\n",
    "pendulum = Pendulum(params)\n",
    "\n",
    "tf = 5.0\n",
    "dt = 0.05\n",
    "N = 5_000\n",
    "\n",
    "theta0 = np.random.uniform(-np.pi, np.pi, (N, 1))\n",
    "omega0 = np.random.uniform(-3, 3, (N, 1))\n",
    "x0 = np.hstack((theta0, omega0))\n",
    "\n",
    "U = generate_random_smooth_controls(N, int(tf/dt))\n",
    "\n",
    "ts, xhist, uhist = simulate_batch(\n",
    "    sys=pendulum,\n",
    "    tf=tf,\n",
    "    dt=dt,\n",
    "    u=U,\n",
    "    x0=x0\n",
    ")\n",
    "\n",
    "split = 0.8\n",
    "N_train = int(N * split)\n",
    "N_eval = N - N_train\n",
    "\n",
    "xhist_train, uhist_train = xhist[:N_train], uhist[:N_train]\n",
    "xhist_eval, uhist_eval = uhist[N_train:], uhist[N_train:]\n"
   ],
   "id": "e4c9628c8d4be433",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulation progress: 100%|██████████| 100/100 [00:00<00:00, 2005.61it/s]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T01:52:38.846811Z",
     "start_time": "2025-04-16T01:52:37.716204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare training\n",
    "traj_per_batch = 5\n",
    "\n",
    "dataset_train = TensorDataset(torch.tensor(xhist_train, dtype=torch.float32),\n",
    "                              torch.tensor(uhist_train, dtype=torch.float32))\n",
    "dataset_eval = TensorDataset(torch.tensor(xhist_eval, dtype=torch.float32),\n",
    "                             torch.tensor(xhist_eval, dtype=torch.float32))\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train,\n",
    "                              batch_size=traj_per_batch,\n",
    "                              shuffle=True)\n",
    "dataloader_eval = DataLoader(dataset_eval,\n",
    "                             batch_size=traj_per_batch,\n",
    "                             shuffle=False)\n",
    "\n",
    "reconstruction_loss = MSELoss()\n",
    "evolution_loss = MSELoss()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "9530b7c0062bb31f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T01:53:32.838755Z",
     "start_time": "2025-04-16T01:53:32.834777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, nx, nz, n_hidden=None):\n",
    "        super().__init__()\n",
    "        if n_hidden is None:\n",
    "            n_hidden = nz\n",
    "        self.nx, self.nz, self.n_hidden = nx, nz, n_hidden\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(nx, n_hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(n_hidden, nz),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(nz, n_hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(n_hidden, nx)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n"
   ],
   "id": "773308e5ea63e7f9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T01:53:29.460349Z",
     "start_time": "2025-04-16T01:53:29.433109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import optim\n",
    "\n",
    "# Train\n",
    "n_epochs = 50\n",
    "nx, nu = 2, 1\n",
    "nz_x = 20\n",
    "nz_u = 20\n",
    "\n",
    "autoenc_x = AutoEncoder(nx, nz_x).to(device)\n",
    "autoenc_u = AutoEncoder(nx, nz_u).to(device)\n",
    "\n",
    "A = torch.nn.Linear(nz_x, nz_x, bias=False).to(device)\n",
    "B = torch.nn.Linear(nz_u, nz_x, bias=False).to(device)\n",
    "nn.init.eye_(A)\n",
    "nn.init.zeros_(B)\n",
    "\n",
    "# Cs = list()\n",
    "# for i in range(nu):\n",
    "#     Ci = torch.nn.Linear(nz_x, nz_u, bias=False).to(device)\n",
    "#     nn.init.zeros_(Ci)\n",
    "#     Cs.append(Ci)\n",
    "\n",
    "\n",
    "mse_loss = MSELoss()\n",
    "\n",
    "theta = chain(autoenc_x.parameters(),\n",
    "              autoenc_u.parameters(),\n",
    "              A.parameters(),\n",
    "              B.parameters(),)\n",
    "              # *[Ci.parameters() for Ci in Cs])\n",
    "\n",
    "optimizer = optim.Adam(theta, lr=1e-3)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "    iterator = tqdm(dataloader_train, total=len(dataloader_train) - 1, desc=\"Training\")\n",
    "    for batch_idx, (x, u) in enumerate(iterator):\n",
    "        # x: (batch_size, traj_len, nx)\n",
    "        x, u = x.to(device), u.to(device)\n",
    "        xp = x[:, 1:]\n",
    "        x, u = torch.reshape(x[:, :-1], (-1, nx)), torch.reshape(u, (-1, nu))\n",
    "        xp = torch.reshape(xp, (-1, nx))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        zx = autoenc_x.encode(x)\n",
    "        zu = autoenc_u.encode(x)\n",
    "        x_rec = autoenc_x.decode(zx)\n",
    "        u_rec = autoenc_u.decode(zu)\n",
    "\n",
    "        reconstr_loss_x = mse_loss(x, x_rec)\n",
    "        reconstr_loss_u = mse_loss(x, u)\n",
    "\n",
    "        xp_pred = autoenc_x.decode(\n",
    "            A(zx) + B(zu)\n",
    "        )\n",
    "        evolution_loss = mse_loss(xp, xp_pred)\n",
    "        loss = reconstr_loss_x + reconstr_loss_u + evolution_loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, L_reconstr,x: {reconstr_loss_x.item():.4f}, \"\n",
    "          f\"L_reconstr,u: {reconstr_loss_u.item():.4f}, \",\n",
    "          f\"L_evolution: {evolution_loss.item():.4f}, \",\n",
    "          f\"L_total: {loss.item():.4f}\")\n",
    "\n"
   ],
   "id": "16a1a6206db0bb01",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, torch.memory_format memory_format = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 9\u001B[0m\n\u001B[1;32m      6\u001B[0m nz_x \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m20\u001B[39m\n\u001B[1;32m      7\u001B[0m nz_u \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m20\u001B[39m\n\u001B[0;32m----> 9\u001B[0m autoenc_x \u001B[38;5;241m=\u001B[39m \u001B[43mAutoEncoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnz_x\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     10\u001B[0m autoenc_u \u001B[38;5;241m=\u001B[39m AutoEncoder(nx, nz_u)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     12\u001B[0m A \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mLinear(nz_x, nz_x, bias\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\u001B[38;5;241m.\u001B[39mto(device)\n",
      "Cell \u001B[0;32mIn[5], line 8\u001B[0m, in \u001B[0;36mAutoEncoder.__init__\u001B[0;34m(self, nx, nz, n_hidden)\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_hidden \u001B[38;5;241m=\u001B[39m nz\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnz \u001B[38;5;241m=\u001B[39m nx, nz\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mSequential(\n\u001B[0;32m----> 8\u001B[0m     \u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLinear\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_hidden\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m      9\u001B[0m     nn\u001B[38;5;241m.\u001B[39mGELU(),\n\u001B[1;32m     10\u001B[0m     nn\u001B[38;5;241m.\u001B[39mLinear(n_hidden, n_hidden),\n\u001B[1;32m     11\u001B[0m     nn\u001B[38;5;241m.\u001B[39mGELU(),\n\u001B[1;32m     12\u001B[0m     nn\u001B[38;5;241m.\u001B[39mLinear(n_hidden, nz),\n\u001B[1;32m     13\u001B[0m )\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mSequential(\n\u001B[1;32m     15\u001B[0m     nn\u001B[38;5;241m.\u001B[39mLinear(nz, n_hidden),\n\u001B[1;32m     16\u001B[0m     nn\u001B[38;5;241m.\u001B[39mGELU(),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     19\u001B[0m     nn\u001B[38;5;241m.\u001B[39mLinear(n_hidden, nx)\n\u001B[1;32m     20\u001B[0m )\n",
      "File \u001B[0;32m~/dev/koopman/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:106\u001B[0m, in \u001B[0;36mLinear.__init__\u001B[0;34m(self, in_features, out_features, bias, device, dtype)\u001B[0m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39min_features \u001B[38;5;241m=\u001B[39m in_features\n\u001B[1;32m    104\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mout_features \u001B[38;5;241m=\u001B[39m out_features\n\u001B[1;32m    105\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight \u001B[38;5;241m=\u001B[39m Parameter(\n\u001B[0;32m--> 106\u001B[0m     \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mempty\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43min_features\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfactory_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    107\u001B[0m )\n\u001B[1;32m    108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m bias:\n\u001B[1;32m    109\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias \u001B[38;5;241m=\u001B[39m Parameter(torch\u001B[38;5;241m.\u001B[39mempty(out_features, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfactory_kwargs))\n",
      "\u001B[0;31mTypeError\u001B[0m: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, torch.memory_format memory_format = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5de111e7af4a6404"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "aabbf62538cbcb17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "73679beb83bb3466"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
